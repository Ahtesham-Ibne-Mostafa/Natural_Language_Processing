{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12140664,"sourceType":"datasetVersion","datasetId":7646062}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport re\nimport spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom string import punctuation\nfrom tqdm import tqdm\ntqdm.pandas()\n\nfile_path = \"/kaggle/input/ehr-mimic-iv/final.csv\"\n\n# Load the latest version\ndf = pd.read_csv(file_path)\n\n\n# Define cardiac-related keywords\ncardiac_keywords = [\n    \"heart\", \"cardiac\", \"cardiovascular\", \"myocardium\", \"pericardium\", \"atrium\", \"atria\",\n    \"ventricle\", \"coronary\", \"ecg\", \"ekg\", \"electrocardiogram\", \"echo\", \"echocardiogram\",\n    \"holter\", \"stress test\", \"troponin\", \"bnp\", \"nt-probnp\", \"myocardial infarction\",\n    \"heart failure\", \"coronary artery disease\", \"cad\", \"arrhythmia\", \"bradycardia\",\n    \"tachycardia\", \"atherosclerosis\", \"angina\", \"atrial fibrillation\", \"afib\",\n    \"ventricular fibrillation\", \"hypertrophic cardiomyopathy\", \"dilated cardiomyopathy\",\n    \"valvular heart disease\", \"congenital heart defect\", \"ischemic heart disease\",\n    \"stent\", \"angioplasty\", \"pacemaker\", \"defibrillator\", \"cabg\"\n]\n\n# Compile regex pattern\npattern = re.compile(r'\\b(?:' + '|'.join(map(re.escape, cardiac_keywords)) + r')\\b', re.IGNORECASE)\n\n# Apply logic to the DataFrame\ndef label_cardiac(text):\n    if pd.isnull(text):\n        return \"No cardiac disease mentioned\"\n    return text if pattern.search(text) else \"No cardiac disease mentioned\"\n\n# Apply to the 'target' column\ndf['target'] = df['target'].apply(label_cardiac)\n\nnlp = spacy.load(\"en_core_web_sm\")\nkeep_words = {\"yes\", \"no\"}\n\n# Make sure \"yes\" and \"no\" are not marked as stopwords in the vocab\nfor word in keep_words:\n    nlp.vocab[word].is_stop = False\n\n# Get current stop words after editing\nstop_words = STOP_WORDS - keep_words\npunctuations = set(punctuation)\n\ndef clean_ehr_text(raw_text):\n    if pd.isnull(raw_text):\n        return []\n\n    remove_sections = [\n        r\"<SEX>.*?(?=<|$)\", r\"<SERVICE>.*?(?=<|$)\", r\"<Age>.*?(?=<|$)\", r\"<Mortality>.*?(?=<|$)\",\n        r\"<Note Type>.*?(?=<|$)\", r\"<ATTENDING>.*?(?=<|$)\", r\"<SOCIAL HISTORY>.*?(?=<|$)\",\n        r\"<FAMILY HISTORY>.*?(?=<|$)\", r\"<DISCHARGE INSTRUCTIONS>.*?(?=<|$)\",\n        r\"<DISCHARGE DISPOSITION>.*?(?=<|$)\", r\"<DISCHARGE DIAGNOSIS>.*?(?=<|$)\",\n        r\"<DISCHARGE CONDITION>.*?(?=<|$)\", r\"<FOLLOWUP INSTRUCTIONS>.*?(?=<|$)\",\n        r\"<DISCHARGE MEDICATIONS>.*?(?=<|$)\", r\"<PAST MEDICAL HISTORY>.*?(?=<|$)\",\n    ]\n\n    combined_pattern = re.compile(\"|\".join(remove_sections), re.IGNORECASE | re.DOTALL)\n    cleaned_text = re.sub(combined_pattern, \"\", raw_text)\n\n    # Format cleanup\n    cleaned_text = re.sub(r'\\n\\s*\\n+', '\\n\\n', cleaned_text).strip()\n    text = cleaned_text\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r\"(</?[A-Z ]+>)\", r\"\\n\\1\\n\", text)\n    text = re.sub(r\"_+\", \"\", text)\n    text = re.sub(r\"\\d{1,2}:\\d{2}\\s*(?:AM|PM)?\", \"\", text, flags=re.IGNORECASE)\n    text = re.sub(r\"[\\.\\:]\\s*___\", \"\", text)\n    text = re.sub(r\"(</?[A-Z ]+>)\", lambda m: m.group(1).upper(), text)\n    text = re.sub(r\"\\s+([,:;])\", r\"\\1\", text)\n    text = re.sub(r\"([,:;])\\s+\", r\"\\1 \", text)\n    text = re.sub(r\"\\s{2,}\", \" \", text)\n    text = re.sub(r\"\\n{2,}\", \"\\n\", text)\n\n    # Tokenize and lemmatize\n    doc = nlp(text.strip())\n    tokens = [\n        token.lemma_.lower().strip()\n        for token in doc\n        if (token.text.lower() in keep_words) or (not token.is_stop and token.text not in punctuations)\n    ]\n    return tokens\n\n\n# ========== Step 4: Apply to DataFrame ==========\n# Assuming your DataFrame is named df and contains 'target' and 'augmented_input'\ndf[\"target_tokens\"] = df[\"target\"].progress_apply(clean_ehr_text)\ndf[\"augmented_input_tokens\"] = df[\"augmented_input\"].progress_apply(clean_ehr_text)\ndf = df[[\"target_tokens\", \"augmented_input_tokens\"]]\n\ndf.to_csv('/kaggle/working/final.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}