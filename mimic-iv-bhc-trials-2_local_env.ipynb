{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8bf43c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)  # This should display the installed version of Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d7140a",
   "metadata": {
    "papermill": {
     "duration": 87.009674,
     "end_time": "2025-01-24T21:54:10.532083",
     "exception": false,
     "start_time": "2025-01-24T21:52:43.522409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load discharge and patient data using the correct local paths\n",
    "df = pd.read_csv(\"/home/ahtesham/Downloads/mimic-iv-ext-bhc-labeled-clinical-notes-dataset-for-hospital-course-summarization-1.1.0/discharge.csv\")\n",
    "df1 = pd.read_csv(\"/home/ahtesham/Downloads/mimic-iv-ext-bhc-labeled-clinical-notes-dataset-for-hospital-course-summarization-1.1.0/patients.csv\")\n",
    "\n",
    "# Display basic information\n",
    "print(df.head())  \n",
    "print(df1.head())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95084602",
   "metadata": {
    "papermill": {
     "duration": 0.017003,
     "end_time": "2025-01-24T21:54:10.556584",
     "exception": false,
     "start_time": "2025-01-24T21:54:10.539581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "print(df.shape)\n",
    "print(f\"----------------------------------------------------\")\n",
    "print(df1.columns)\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeff7fe",
   "metadata": {
    "papermill": {
     "duration": 61.927734,
     "end_time": "2025-01-24T21:55:12.491147",
     "exception": false,
     "start_time": "2025-01-24T21:54:10.563413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"/home/ahtesham/Downloads/mimic-iv-ext-bhc-labeled-clinical-notes-dataset-for-hospital-course-summarization-1.1.0/mimic-iv-bhc.csv\")\n",
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189231dc",
   "metadata": {
    "papermill": {
     "duration": 0.389264,
     "end_time": "2025-01-24T21:55:12.887602",
     "exception": false,
     "start_time": "2025-01-24T21:55:12.498338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for missing values in each dataframe\n",
    "print(df.isnull().sum()) \n",
    "print(\"-----------------------------\")\n",
    "print(df1.isnull().sum())\n",
    "print(\"-----------------------------\")\n",
    "print(df2.isnull().sum())\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "# Inspect data distributions for key columns (e.g., age and gender)\n",
    "print(df1['gender'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df1['anchor_age'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc949c0",
   "metadata": {
    "papermill": {
     "duration": 0.562759,
     "end_time": "2025-01-24T21:55:13.459346",
     "exception": false,
     "start_time": "2025-01-24T21:55:12.896587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill missing values for df\n",
    "df['storetime'].fillna(df['storetime'].mode()[0], inplace=True)  # Replace with mode (most frequent value)\n",
    "\n",
    "# Fill missing values for df1\n",
    "df1['dod'].fillna('NA', inplace=True)  # Replace missing 'dod' with 'NA' to indicate not applicable\n",
    "\n",
    "# Verifying that there are no missing values\n",
    "print(df.isnull().sum())\n",
    "print(df1.isnull().sum())\n",
    "print(df2.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129dd24",
   "metadata": {
    "papermill": {
     "duration": 0.362078,
     "end_time": "2025-01-24T21:55:13.829958",
     "exception": false,
     "start_time": "2025-01-24T21:55:13.467880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the datasets on 'subject_id'\n",
    "merged_df = pd.merge(df2, df, on='note_id', how='inner')\n",
    "\n",
    "print(merged_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2df6de5-388d-4acd-8347-73ffea59a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df1, merged_df, on='subject_id', how='inner')\n",
    "\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d904a6-394c-40fa-9674-5a4d1708fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba410f-d735-48e2-bd32-6e916a774c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787b309a-8e53-4272-9a03-1d70770f3859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df52a0",
   "metadata": {
    "papermill": {
     "duration": 0.016444,
     "end_time": "2025-01-24T21:55:13.856470",
     "exception": false,
     "start_time": "2025-01-24T21:55:13.840026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save the merged DataFrame to a new CSV file\n",
    "# #  merged_df.to_csv(\"D:/THESIS/dataset02/merged_data.csv\", index=False)\n",
    "\n",
    "# print(\"Merged dataset saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1f50cb",
   "metadata": {
    "papermill": {
     "duration": 0.026892,
     "end_time": "2025-01-24T21:55:13.892453",
     "exception": false,
     "start_time": "2025-01-24T21:55:13.865561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93e249",
   "metadata": {
    "papermill": {
     "duration": 0.205343,
     "end_time": "2025-01-24T21:55:14.105185",
     "exception": false,
     "start_time": "2025-01-24T21:55:13.899842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(merged_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c6ef6-9549-41d6-a460-6a1b848b7525",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd74db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure the 'gender' column exists\n",
    "if 'gender' in merged_df.columns:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x=merged_df['gender'])\n",
    "    plt.title(\"Gender Distribution in merged_df\")\n",
    "    plt.xlabel(\"Gender\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"The 'gender' column is not found in merged_df.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e718673",
   "metadata": {
    "papermill": {
     "duration": 4.416908,
     "end_time": "2025-01-24T21:55:18.531085",
     "exception": false,
     "start_time": "2025-01-24T21:55:14.114177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merged_df['text_length'] = merged_df['text'].apply(len)\n",
    "\n",
    "# # Basic statistics for text length\n",
    "# print(merged_df['text_length'].describe())\n",
    "\n",
    "# # Plotting the distribution of text length\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# sns.histplot(merged_df['text_length'], kde=True)\n",
    "# plt.xlabel('Text Length')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Text Length Distribution')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4feef58",
   "metadata": {
    "papermill": {
     "duration": 0.017894,
     "end_time": "2025-01-24T21:55:18.557581",
     "exception": false,
     "start_time": "2025-01-24T21:55:18.539687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_entry = merged_df.loc[52, 'target']\n",
    "print(first_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b45f1f0-811b-4b41-bc4e-1361b874b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_entry_1 = merged_df.loc[52, 'text']\n",
    "print(first_entry_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d546bf-5211-4cfb-a36e-9460e3540f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_entry_2 = merged_df.loc[52, 'input']\n",
    "print(first_entry_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5943a8d2",
   "metadata": {
    "papermill": {
     "duration": 50.395297,
     "end_time": "2025-01-24T21:56:08.966206",
     "exception": false,
     "start_time": "2025-01-24T21:55:18.570909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example search for mentions of 'ecg' in the 'text' column\n",
    "ecg_mentions = merged_df[merged_df['text'].str.contains('ecg', case=False, na=False)]\n",
    "\n",
    "print(ecg_mentions[['text']].head(25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a93432e-f381-4649-a53e-f30d2cecb3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop('text', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40fcaa7-9d67-46aa-918b-6fa8974f0021",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e4cddb",
   "metadata": {
    "papermill": {
     "duration": 99.787652,
     "end_time": "2025-01-24T21:57:48.762512",
     "exception": false,
     "start_time": "2025-01-24T21:56:08.974860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count the total number of times 'ecg' is mentioned across the 'text' column\n",
    "ecg_count = merged_df['text'].str.contains('ecg', case=False, na=False).sum()\n",
    "# Count only one mention of 'ecg' per row\n",
    "ecg_mention_per_row = merged_df['text'].str.contains('ecg', case=False, na=False).sum()\n",
    "\n",
    "print(f\"ECG was mentioned {ecg_count} times.\")\n",
    "print(f\"ECG was mentioned at least once in {ecg_mention_per_row} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c2e39c",
   "metadata": {
    "papermill": {
     "duration": 0.016883,
     "end_time": "2025-01-24T21:57:48.788077",
     "exception": false,
     "start_time": "2025-01-24T21:57:48.771194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_size = merged_df.shape\n",
    "print(f\"The dataset has {dataset_size[0]} rows and {dataset_size[1]} columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887b901",
   "metadata": {
    "papermill": {
     "duration": 49.581828,
     "end_time": "2025-01-24T21:58:38.378541",
     "exception": false,
     "start_time": "2025-01-24T21:57:48.796713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df['has_ecg'] = merged_df['text'].str.contains('ecg', case=False, na=False).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312899c",
   "metadata": {
    "papermill": {
     "duration": 0.018568,
     "end_time": "2025-01-24T21:58:38.413318",
     "exception": false,
     "start_time": "2025-01-24T21:58:38.394750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(merged_df.columns)\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "dataset_size = merged_df.shape\n",
    "print(f\"The dataset has {dataset_size[0]} rows and {dataset_size[1]} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7aaab",
   "metadata": {
    "papermill": {
     "duration": 0.038521,
     "end_time": "2025-01-24T21:58:38.460568",
     "exception": false,
     "start_time": "2025-01-24T21:58:38.422047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9779db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'has_ecg' not in merged_df.columns:\n",
    "    raise KeyError(\"The column 'has_ecg' is missing in merged_df.\")\n",
    "\n",
    "# Count the number of records with and without ECG\n",
    "ecg_counts = merged_df['has_ecg'].value_counts().sort_index()  # Sorts so 0 (No ECG) comes first\n",
    "\n",
    "# Define labels based on sorted order\n",
    "labels = ['No ECG', 'Has ECG']  # Ensure correct label order\n",
    "\n",
    "# Display value counts\n",
    "print(\"ECG Availability Counts:\")\n",
    "print(ecg_counts)\n",
    "\n",
    "# Plot pie chart\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(ecg_counts, labels=labels, autopct='%1.1f%%', startangle=90, wedgeprops={'edgecolor': 'black'})\n",
    "plt.title(\"Distribution of ECG Availability in merged_df\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1a999b",
   "metadata": {
    "papermill": {
     "duration": 0.010894,
     "end_time": "2025-01-24T21:58:38.480692",
     "exception": false,
     "start_time": "2025-01-24T21:58:38.469798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It's the third csv mimic-iv-bhc trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecbcff7",
   "metadata": {
    "papermill": {
     "duration": 0.023029,
     "end_time": "2025-01-24T21:58:38.513102",
     "exception": false,
     "start_time": "2025-01-24T21:58:38.490073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b21a02",
   "metadata": {
    "papermill": {
     "duration": 0.017502,
     "end_time": "2025-01-24T21:58:38.540167",
     "exception": false,
     "start_time": "2025-01-24T21:58:38.522665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d37e0a",
   "metadata": {
    "papermill": {
     "duration": 0.019169,
     "end_time": "2025-01-24T21:58:38.568526",
     "exception": false,
     "start_time": "2025-01-24T21:58:38.549357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df2.loc[0, \"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3032e61",
   "metadata": {
    "papermill": {
     "duration": 0.017765,
     "end_time": "2025-01-24T21:58:38.595875",
     "exception": false,
     "start_time": "2025-01-24T21:58:38.578110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df2.loc[0, \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c3690",
   "metadata": {
    "papermill": {
     "duration": 0.016023,
     "end_time": "2025-01-24T21:58:38.621919",
     "exception": false,
     "start_time": "2025-01-24T21:58:38.605896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merged_df.to_csv(\"/kaggle/working/mimic-iv-bhc-patient_discharge_merged.csv\", index=False)\n",
    "#print(\"Merged dataframe saved as 'mimic-iv-bhc-patient_discharge_merged.csv' in the Kaggle working directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3fb5f",
   "metadata": {
    "papermill": {
     "duration": 0.032036,
     "end_time": "2025-01-24T21:58:38.663409",
     "exception": false,
     "start_time": "2025-01-24T21:58:38.631373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows = [18, 20, 25, 46, 52, 56, 63, 71, 96, 149]\n",
    "texts = merged_df.loc[rows, 'text'].tolist()  # Convert the 'text' column values to a list\n",
    "for i, text in zip(rows, texts):\n",
    "    print(f\"Row {i}\\n--------------------------------------------------------------:\\n--------------------------------------------------------------: {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e1de52",
   "metadata": {
    "papermill": {
     "duration": 0.032072,
     "end_time": "2025-01-24T21:58:38.713553",
     "exception": false,
     "start_time": "2025-01-24T21:58:38.681481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16715673",
   "metadata": {},
   "source": [
    "## didn't fetch the correct portion of the text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace07c1",
   "metadata": {
    "papermill": {
     "duration": 55.701963,
     "end_time": "2025-01-24T21:59:34.428616",
     "exception": false,
     "start_time": "2025-01-24T21:58:38.726653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# didn't fetch the correct portion of the text \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Filter rows containing \"ECG\" in the text column\n",
    "ecg_rows = merged_df[merged_df['text'].str.contains('ECG', case=False, na=False)]\n",
    "\n",
    "# Function to extract fields from the text\n",
    "def extract_field(text, field_name):\n",
    "    try:\n",
    "        start = text.lower().index(field_name.lower()) + len(field_name) + 1\n",
    "        end = text[start:].find(\"\\n\")\n",
    "        return text[start:start + end].strip() if end != -1 else text[start:].strip()\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# List of fields to extract\n",
    "fields = [\n",
    "    \"Sex\",\n",
    "    \"Chief Complaint\",\n",
    "    \"History of Present Illness\",\n",
    "    \"Past Medical History\",\n",
    "    \"Family History\",\n",
    "    \"Physical Exam\",\n",
    "    \"Admission Exam\"\n",
    "]\n",
    "\n",
    "# Create a new dataframe with extracted fields\n",
    "extracted_data = []\n",
    "for _, row in ecg_rows.iterrows():\n",
    "    text = row['text']\n",
    "    extracted_row = {field: extract_field(text, field) for field in fields}\n",
    "    extracted_data.append(extracted_row)\n",
    "\n",
    "result_df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Display or save the result dataframe\n",
    "print(result_df)\n",
    "display(result_df)\n",
    "\n",
    "# Uncomment below to save the result to a CSV\n",
    "# result_df.to_csv('extracted_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1edada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# didn't fetch the correct portion of the text \n",
    "first_row = result_df.iloc[52].to_dict() if not result_df.empty else \"The result_df dataframe is empty.\"\n",
    "first_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d9929",
   "metadata": {
    "papermill": {
     "duration": 67.160522,
     "end_time": "2025-01-24T22:00:41.602392",
     "exception": false,
     "start_time": "2025-01-24T21:59:34.441870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming merged_df is already defined and contains a column 'text'\n",
    "\n",
    "# Function to extract the paragraph following a specific field\n",
    "def extract_field(text, field_name):\n",
    "    try:\n",
    "        start = text.lower().index(field_name.lower()) + len(field_name) + 1\n",
    "        # Find the next blank line (or end of text)\n",
    "        end = text[start:].find(\"\\n\\n\")\n",
    "        return text[start:start + end].strip() if end != -1 else text[start:].strip()\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# List of fields to extract\n",
    "fields = [\n",
    "    \"Sex\",\n",
    "    \"Chief Complaint\",\n",
    "    \"History of Present Illness\",\n",
    "    \"Past Medical History\",\n",
    "    \"Family History\",\n",
    "    \"Physical Exam\",\n",
    "    \"Admission Exam\"\n",
    "]\n",
    "\n",
    "# Create a new dataframe with extracted fields\n",
    "extracted_data = []\n",
    "for _, row in merged_df.iterrows():\n",
    "    text = row['text']\n",
    "    extracted_row = {field: extract_field(text, field) for field in fields}\n",
    "    extracted_data.append(extracted_row)\n",
    "\n",
    "# Create the result dataframe\n",
    "result_df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Display the result\n",
    "print(\"First Row of Extracted Data:\")\n",
    "print(result_df.head(1))\n",
    "\n",
    "# Uncomment to save to a CSV file\n",
    "# result_df.to_csv('extracted_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c303a7",
   "metadata": {
    "papermill": {
     "duration": 66.696202,
     "end_time": "2025-01-24T22:01:48.311654",
     "exception": false,
     "start_time": "2025-01-24T22:00:41.615452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming merged_df is already defined and contains a column 'text'\n",
    "\n",
    "# Function to extract the paragraph following a specific field\n",
    "def extract_field(text, field_name):\n",
    "    try:\n",
    "        start = text.lower().index(field_name.lower()) + len(field_name) + 1\n",
    "        # Find the next blank line (or end of text)\n",
    "        end = text[start:].find(\"\\n\\n\")\n",
    "        return text[start:start + end].strip() if end != -1 else text[start:].strip()\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# List of fields to extract\n",
    "fields = [\n",
    "    \"Sex\",\n",
    "    \"Chief Complaint\",\n",
    "    \"History of Present Illness\",\n",
    "    \"Past Medical History\",\n",
    "    \"Family History\",\n",
    "    \"Physical Exam\",\n",
    "    \"Admission Exam\"\n",
    "]\n",
    "\n",
    "# Create a new dataframe with extracted fields\n",
    "extracted_data = []\n",
    "for _, row in merged_df.iterrows():\n",
    "    text = row['text']\n",
    "    extracted_row = {field: extract_field(text, field) for field in fields}\n",
    "    extracted_data.append(extracted_row)\n",
    "\n",
    "# Create the result dataframe\n",
    "result_df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Display the result\n",
    "print(\"First Row of Extracted Data:\")\n",
    "# print(result_df.head(1))\n",
    "display(result_df.head(1))\n",
    "\n",
    "# Uncomment to save to a CSV file\n",
    "# result_df.to_csv('extracted_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52670c8",
   "metadata": {
    "papermill": {
     "duration": 0.022679,
     "end_time": "2025-01-24T22:01:48.347353",
     "exception": false,
     "start_time": "2025-01-24T22:01:48.324674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Displaying only the first row of the result_df dataframe to visualize all extracted data\n",
    "first_row = result_df.iloc[0].to_dict() if not result_df.empty else \"The result_df dataframe is empty.\"\n",
    "first_row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd0a39b",
   "metadata": {},
   "source": [
    "In previous code the finding of end of section was wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb581161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to extract the text section between fields\n",
    "def extract_field(text, field_name, all_fields):\n",
    "    try:\n",
    "        # Find start position of the given field\n",
    "        start = text.lower().index(field_name.lower()) + len(field_name) + 1\n",
    "\n",
    "        # Find the next field that comes after the current field\n",
    "        next_positions = []\n",
    "        for other_field in all_fields:\n",
    "            if other_field.lower() in text.lower()[start:]:\n",
    "                next_positions.append(text.lower().index(other_field.lower(), start))\n",
    "\n",
    "        # If there is a next section, cut text at that position\n",
    "        end = min(next_positions) if next_positions else len(text)\n",
    "\n",
    "        return text[start:end].strip()\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# List of fields to extract\n",
    "fields = [\n",
    "    \"Sex\",\n",
    "    \"Chief Complaint\",\n",
    "    \"History of Present Illness\",\n",
    "    \"Past Medical History\",\n",
    "    \"Family History\",\n",
    "    \"Physical Exam\",\n",
    "    \"Admission Exam\"\n",
    "]\n",
    "\n",
    "# Extract fields for each row in merged_df\n",
    "extracted_data = []\n",
    "for _, row in merged_df.iterrows():\n",
    "    text = row['text']\n",
    "    extracted_row = {field: extract_field(text, field, fields) for field in fields}\n",
    "    extracted_data.append(extracted_row)\n",
    "\n",
    "# Create the result dataframe\n",
    "result_df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Display the result\n",
    "display(result_df.head(1))  # Show the first row for verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9028acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to extract the text section between fields\n",
    "def extract_field(text, field_name, all_fields):\n",
    "    try:\n",
    "        # Find start position of the given field\n",
    "        start = text.lower().index(field_name.lower()) + len(field_name) + 1\n",
    "\n",
    "        # Find the next field that comes after the current field\n",
    "        next_positions = []\n",
    "        for other_field in all_fields:\n",
    "            if other_field.lower() in text.lower()[start:]:\n",
    "                next_positions.append(text.lower().index(other_field.lower(), start))\n",
    "\n",
    "        # Determine the end position as the next closest field or the end of the text\n",
    "        end = min(next_positions) if next_positions else len(text)\n",
    "\n",
    "        return text[start:end].strip()\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# **List of all required sections**\n",
    "fields = [\n",
    "    \"Sex\",\n",
    "    \"Service\",\n",
    "    \"Allergies\",\n",
    "    \"Known Allergies\",\n",
    "    \"Attending\",\n",
    "    \"Chief Complaint\",\n",
    "    \"History of Present Illness\",\n",
    "    \"Past Medical History\",\n",
    "    \"Family History\",\n",
    "    \"Physical Exam\",\n",
    "    \"Admission Exam\",\n",
    "    \"Discharge Exam\",\n",
    "    \"Pertinent Results\",\n",
    "    \"Imaging\",\n",
    "    \"Brief Hospital Course\",\n",
    "    \"Transitional Issues\",\n",
    "    \"Medications on Admission\",\n",
    "    \"Discharge Medications\",\n",
    "    \"Discharge Disposition\",\n",
    "    \"Discharge Diagnosis\",\n",
    "    \"Discharge Condition\",\n",
    "    \"Discharge Instructions\",\n",
    "    \"Follow-up Instructions\"\n",
    "]\n",
    "\n",
    "# Extract fields for each row in merged_df\n",
    "extracted_data = []\n",
    "for _, row in merged_df.iterrows():\n",
    "    text = row['text']\n",
    "    extracted_row = {field: extract_field(text, field, fields) for field in fields}\n",
    "    extracted_data.append(extracted_row)\n",
    "\n",
    "# Create the final result dataframe\n",
    "final_df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Display the extracted data\n",
    "display(final_df.head(5))  # Show the first 5 rows for verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2f84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying only the first row of the result_df dataframe to visualize all extracted data\n",
    "first_row = result_df.iloc[0].to_dict() if not result_df.empty else \"The result_df dataframe is empty.\"\n",
    "first_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying only the first row of the final_df dataframe to visualize all extracted data\n",
    "first_row = final_df.iloc[0].to_dict() if not final_df.empty else \"The final_df dataframe is empty.\"\n",
    "first_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4493efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the selected columns to be placed first\n",
    "selected_columns = ['subject_id', 'gender', 'note_id', 'note_seq', 'has_ecg']\n",
    "\n",
    "# Ensure merged_df and final_df exist\n",
    "if 'merged_df' not in globals() or 'final_df' not in globals():\n",
    "    raise NameError(\"Both merged_df and final_df must be defined before running this code.\")\n",
    "\n",
    "# Ensure the selected columns exist in merged_df\n",
    "missing_columns = [col for col in selected_columns if col not in merged_df.columns]\n",
    "if missing_columns:\n",
    "    raise KeyError(f\"Missing columns in merged_df: {missing_columns}\")\n",
    "\n",
    "# Create final_df with selected columns from merged_df first, followed by all columns from result_df\n",
    "final_df = pd.concat([merged_df[selected_columns], final_df], axis=1)\n",
    "\n",
    "# Display the updated final_df in a Jupyter Notebook\n",
    "display(final_df)  # Use this instead of print() in Jupyter Notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd0b4a9",
   "metadata": {
    "papermill": {
     "duration": 0.022626,
     "end_time": "2025-01-24T22:01:48.418921",
     "exception": false,
     "start_time": "2025-01-24T22:01:48.396295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking and displaying the \"History of Present Illness\" field from the first row of result_df\n",
    "present_illness_first_row = result_df.iloc[0][\"History of Present Illness\"] if not result_df.empty else \"The result_df dataframe is empty.\"\n",
    "present_illness_first_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c2657",
   "metadata": {
    "papermill": {
     "duration": 67.095126,
     "end_time": "2025-01-24T22:02:55.527410",
     "exception": false,
     "start_time": "2025-01-24T22:01:48.432284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting any sentence or paragraph containing \"ECG\" from the \"text\" column in merged_df\n",
    "if 'merged_df' in locals() and 'text' in merged_df.columns:\n",
    "    ecg_texts = merged_df[merged_df['text'].str.contains('ECG', case=False, na=False)]['text']\n",
    "    ecg_paragraphs = ecg_texts.str.extract(r'((?:.*ECG.*(?:\\n|$))+)') if not ecg_texts.empty else \"No ECG-related content found.\"\n",
    "else:\n",
    "    ecg_paragraphs = \"The merged_df dataframe or 'text' column does not exist.\"\n",
    "\n",
    "ecg_paragraphs.head(10) if isinstance(ecg_paragraphs, pd.DataFrame) else ecg_paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c16e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame that only includes rows where 'has_ecg' is 1\n",
    "final_df_with_ecg = final_df[final_df['has_ecg'] == 1]\n",
    " \n",
    "display(final_df_with_ecg)  # Works in Jupyter Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path for saving the CSV\n",
    "# save_path = \"D:/THESIS/dataset02/final_df_with_ecg.csv\"\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "# final_df_with_ecg.to_csv(save_path, index=False)\n",
    "\n",
    "# print(f\"CSV file saved successfully at: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba14e91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5881985,
     "sourceId": 9637445,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 687.3123,
   "end_time": "2025-01-24T22:04:08.022598",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-24T21:52:40.710298",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
