{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c7c327-47a2-4900-b99e-a0dfd3f60844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2454af7-c545-4354-970c-231ad72ba741",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"D:\\archive\\final.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd1d4d2-cf20-4084-9406-ea4dcdbfdecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64790ad0-ccd3-4a62-9930-1516675426c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;ALLERGIES&gt; No Known Allergies / Adverse Drug...</td>\n",
       "      <td>HCV cirrhosis c/b ascites, hiv on ART, h/o IV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;ALLERGIES&gt; Percocet &lt;CHIEF COMPLAINT&gt; abdomi...</td>\n",
       "      <td>with HIV on HAART, HCV cirrhosis with ascites...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;ALLERGIES&gt; omeprazole &lt;CHIEF COMPLAINT&gt; dysp...</td>\n",
       "      <td>No cardiac disease mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;ALLERGIES&gt; omeprazole / Iodine and Iodide Co...</td>\n",
       "      <td>No cardiac disease mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;ALLERGIES&gt; No Known Allergies / Adverse Drug...</td>\n",
       "      <td>No cardiac disease mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270028</th>\n",
       "      <td>&lt;ALLERGIES&gt; No Known Allergies / Adverse Drug...</td>\n",
       "      <td>No cardiac disease mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270029</th>\n",
       "      <td>&lt;ALLERGIES&gt; Lamictal / hydrochlorothiazide &lt;C...</td>\n",
       "      <td>No cardiac disease mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270030</th>\n",
       "      <td>&lt;ALLERGIES&gt; Patient recorded as having No Kno...</td>\n",
       "      <td>No cardiac disease mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270031</th>\n",
       "      <td>&lt;ALLERGIES&gt; Patient recorded as having No Kno...</td>\n",
       "      <td>Mr. was admitted with status epilepticus. His ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270032</th>\n",
       "      <td>&lt;ALLERGIES&gt; No Known Allergies / Adverse Drug...</td>\n",
       "      <td>This is a year old woman with a history of Lym...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270033 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0        <ALLERGIES> No Known Allergies / Adverse Drug...   \n",
       "1        <ALLERGIES> Percocet <CHIEF COMPLAINT> abdomi...   \n",
       "2        <ALLERGIES> omeprazole <CHIEF COMPLAINT> dysp...   \n",
       "3        <ALLERGIES> omeprazole / Iodine and Iodide Co...   \n",
       "4        <ALLERGIES> No Known Allergies / Adverse Drug...   \n",
       "...                                                   ...   \n",
       "270028   <ALLERGIES> No Known Allergies / Adverse Drug...   \n",
       "270029   <ALLERGIES> Lamictal / hydrochlorothiazide <C...   \n",
       "270030   <ALLERGIES> Patient recorded as having No Kno...   \n",
       "270031   <ALLERGIES> Patient recorded as having No Kno...   \n",
       "270032   <ALLERGIES> No Known Allergies / Adverse Drug...   \n",
       "\n",
       "                                                    label  \n",
       "0        HCV cirrhosis c/b ascites, hiv on ART, h/o IV...  \n",
       "1        with HIV on HAART, HCV cirrhosis with ascites...  \n",
       "2                            No cardiac disease mentioned  \n",
       "3                            No cardiac disease mentioned  \n",
       "4                            No cardiac disease mentioned  \n",
       "...                                                   ...  \n",
       "270028                       No cardiac disease mentioned  \n",
       "270029                       No cardiac disease mentioned  \n",
       "270030                       No cardiac disease mentioned  \n",
       "270031  Mr. was admitted with status epilepticus. His ...  \n",
       "270032  This is a year old woman with a history of Lym...  \n",
       "\n",
       "[270033 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1288ed1-a720-4f44-a2be-5a048b3189c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: torch in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn transformers torch tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dbecab-def7-48da-9db9-edb7538e3fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['augmented_input_tokens']\n",
    "df['label'] = df['target_tokens']\n",
    "df = df[[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "521ad7ee-e57b-4f82-8521-5334bfe0c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "636da2b5-f918-4e6f-950c-21e3b63753fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahtes\\anaconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Load tokenizer\n",
    "model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenization function (batch-safe)\n",
    "def batch_tokenize(texts, batch_size=100):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Tokenizing\"):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        encodings = tokenizer(\n",
    "            batch_texts,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"  # returns PyTorch tensors directly\n",
    "        )\n",
    "        input_ids.append(encodings['input_ids'])\n",
    "        attention_masks.append(encodings['attention_mask'])\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    all_input_ids = torch.cat(input_ids)\n",
    "    all_attention_masks = torch.cat(attention_masks)\n",
    "    return all_input_ids, all_attention_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "744cd3ba-3f96-49a1-acab-b39c596abfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████| 3376/3376 [02:27<00:00, 22.83it/s]\n",
      "Tokenizing: 100%|██████████| 844/844 [00:43<00:00, 19.25it/s]\n"
     ]
    }
   ],
   "source": [
    "train_input_ids, train_attention_masks = batch_tokenize(list(train_texts), batch_size=64)\n",
    "val_input_ids, val_attention_masks = batch_tokenize(list(val_texts), batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f62e49e-0f73-4829-9146-25cac9811032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "\n",
    "# Initialize encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit on all labels (both train + val to avoid unseen values in val)\n",
    "all_labels = train_labels + val_labels\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Transform string labels to integer labels\n",
    "train_labels_encoded = label_encoder.transform(train_labels)\n",
    "val_labels_encoded = label_encoder.transform(val_labels)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_labels_tensor = torch.tensor(train_labels_encoded)\n",
    "val_labels_tensor = torch.tensor(val_labels_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a209bf-1b4a-458e-9b4f-8f98309f2397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae0aea-2701-40a8-b139-5d54559097dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ehr_model\",\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds)\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cb5e85-d713-4ad6-bac5-33c0a17a72c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
